# ğŸ“˜ Tokens e Janela de Contexto em Modelos de Linguagem (LLMs)

Este registro faz parte do meu **Daily Code Journal**, com o objetivo de consolidar conceitos fundamentais sobre como funcionam os modelos de linguagem modernos (LLMs), como ChatGPT, Gemini, Claude, entre outros.

---

## âœ… O que sÃ£o Tokens?

Tokens sÃ£o as **menores unidades de texto** que um modelo de linguagem utiliza para processar informaÃ§Ãµes. Eles podem ser:

* Palavras inteiras
* Partes de palavras
* SÃ­mbolos
* Caracteres individuais

### Exemplos:

* "computador" â†’ pode ser 1 token
* "programaÃ§Ã£o" â†’ pode ser dividida em `programa` + `Ã§Ã£o`
* "AI" â†’ pode ser 1 token

Os modelos **nÃ£o leem texto como humanos**, eles interpretam tudo em forma de tokens.

---

## âœ… O que Ã© a Janela de Contexto?

A **janela de contexto** define **quantos tokens o modelo consegue processar por vez**, considerando:

* A entrada do usuÃ¡rio
* O histÃ³rico da conversa
* A resposta gerada

Ela funciona como uma espÃ©cie de **memÃ³ria temporÃ¡ria** do modelo.

### Exemplo prÃ¡tico:

Se um modelo possui uma janela de contexto de 8.000 tokens, isso significa que toda a conversa + resposta **nÃ£o pode ultrapassar esse limite ao mesmo tempo**.

---

## âœ… O que acontece quando o limite da janela Ã© atingido?

Quando o limite Ã© alcanÃ§ado:

* âœ… Os **tokens mais antigos sÃ£o descartados**
* âœ… Os **tokens mais novos entram no lugar**
* âŒ O modelo **nÃ£o armazena memÃ³ria permanente**

Isso significa que o modelo pode **"esquecer" informaÃ§Ãµes antigas da conversa** conforme novas mensagens sÃ£o enviadas.

---

## âœ… ImportÃ¢ncia de um Prompt Claro e Objetivo

Uma instruÃ§Ã£o clara evita:

* âŒ InterpretaÃ§Ãµes erradas
* âŒ Respostas genÃ©ricas
* âŒ Perda de tempo e tokens

Um bom prompt deve conter:

* Contexto correto
* Objetivo claro
* Formato esperado da resposta

### Exemplo:

âŒ Prompt ruim:

> "Me ajude com cÃ³digo"

âœ… Prompt bom:

> "Crie uma funÃ§Ã£o em Python que valide se um nÃºmero Ã© par ou Ã­mpar e retorne o resultado em texto."

---

## âœ… ConclusÃ£o

Compreender **tokens, janela de contexto e a importÃ¢ncia dos prompts** Ã© essencial para:

* Usar LLMs de forma profissional
* Oportunizar melhores respostas
* Evitar desperdÃ­cio de recursos
* Criar aplicaÃ§Ãµes mais eficientes com IA

---

ğŸ“… *Registro feito no Daily Code Journal*

Se vocÃª estuda IA, este Ã© um dos conceitos mais importantes para dominar logo no inÃ­cio da jornada.
